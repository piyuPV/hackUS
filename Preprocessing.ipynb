{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39045852-0961-455c-9ac5-5ea6cb9f5120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piyus\\anaconda3\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: SandalWoodNewsStories_1.wav\n",
      "Transcription saved for: SandalWoodNewsStories_1.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_1.wav\n",
      "Processing file: SandalWoodNewsStories_107.wav\n",
      "Transcription saved for: SandalWoodNewsStories_107.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_107.wav\n",
      "Processing file: SandalWoodNewsStories_112.wav\n",
      "Transcription saved for: SandalWoodNewsStories_112.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_112.wav\n",
      "Processing file: SandalWoodNewsStories_144.wav\n",
      "Transcription saved for: SandalWoodNewsStories_144.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_144.wav\n",
      "Processing file: SandalWoodNewsStories_146.wav\n",
      "Transcription saved for: SandalWoodNewsStories_146.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_146.wav\n",
      "Processing file: SandalWoodNewsStories_148.wav\n",
      "Transcription saved for: SandalWoodNewsStories_148.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_148.wav\n",
      "Processing file: SandalWoodNewsStories_156.wav\n",
      "Transcription saved for: SandalWoodNewsStories_156.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_156.wav\n",
      "Processing file: SandalWoodNewsStories_158.wav\n",
      "Transcription saved for: SandalWoodNewsStories_158.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_158.wav\n",
      "Processing file: SandalWoodNewsStories_159.wav\n",
      "Transcription saved for: SandalWoodNewsStories_159.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_159.wav\n",
      "Processing file: SandalWoodNewsStories_167.wav\n",
      "Transcription saved for: SandalWoodNewsStories_167.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_167.wav\n",
      "Processing file: SandalWoodNewsStories_168.wav\n",
      "Transcription saved for: SandalWoodNewsStories_168.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_168.wav\n",
      "Processing file: SandalWoodNewsStories_169.wav\n",
      "Transcription saved for: SandalWoodNewsStories_169.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_169.wav\n",
      "Processing file: SandalWoodNewsStories_171.wav\n",
      "Transcription saved for: SandalWoodNewsStories_171.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_171.wav\n",
      "Processing file: SandalWoodNewsStories_172.wav\n",
      "Transcription saved for: SandalWoodNewsStories_172.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_172.wav\n",
      "Processing file: SandalWoodNewsStories_173.wav\n",
      "Transcription saved for: SandalWoodNewsStories_173.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_173.wav\n",
      "Processing file: SandalWoodNewsStories_174.wav\n",
      "Transcription saved for: SandalWoodNewsStories_174.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_174.wav\n",
      "Processing file: SandalWoodNewsStories_175.wav\n",
      "Transcription saved for: SandalWoodNewsStories_175.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_175.wav\n",
      "Processing file: SandalWoodNewsStories_176.wav\n",
      "Transcription saved for: SandalWoodNewsStories_176.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_176.wav\n",
      "Processing file: SandalWoodNewsStories_179.wav\n",
      "Transcription saved for: SandalWoodNewsStories_179.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_179.wav\n",
      "Processing file: SandalWoodNewsStories_181.wav\n",
      "Transcription saved for: SandalWoodNewsStories_181.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_181.wav\n",
      "Processing file: SandalWoodNewsStories_184.wav\n",
      "Transcription saved for: SandalWoodNewsStories_184.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_184.wav\n",
      "Processing file: SandalWoodNewsStories_191.wav\n",
      "Transcription saved for: SandalWoodNewsStories_191.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_191.wav\n",
      "Processing file: SandalWoodNewsStories_197.wav\n",
      "Transcription saved for: SandalWoodNewsStories_197.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_197.wav\n",
      "Processing file: SandalWoodNewsStories_2.wav\n",
      "Transcription saved for: SandalWoodNewsStories_2.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_2.wav\n",
      "Processing file: SandalWoodNewsStories_200.wav\n",
      "Transcription saved for: SandalWoodNewsStories_200.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_200.wav\n",
      "Processing file: SandalWoodNewsStories_211.wav\n",
      "Transcription saved for: SandalWoodNewsStories_211.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_211.wav\n",
      "Processing file: SandalWoodNewsStories_215.wav\n",
      "Transcription saved for: SandalWoodNewsStories_215.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_215.wav\n",
      "Processing file: SandalWoodNewsStories_223.wav\n",
      "Transcription saved for: SandalWoodNewsStories_223.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_223.wav\n",
      "Processing file: SandalWoodNewsStories_229.wav\n",
      "Transcription saved for: SandalWoodNewsStories_229.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_229.wav\n",
      "Processing file: SandalWoodNewsStories_23.wav\n",
      "Transcription saved for: SandalWoodNewsStories_23.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_23.wav\n",
      "Processing file: SandalWoodNewsStories_230.wav\n",
      "Transcription saved for: SandalWoodNewsStories_230.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_230.wav\n",
      "Processing file: SandalWoodNewsStories_239.wav\n",
      "Transcription saved for: SandalWoodNewsStories_239.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_239.wav\n",
      "Processing file: SandalWoodNewsStories_242.wav\n",
      "Transcription saved for: SandalWoodNewsStories_242.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_242.wav\n",
      "Processing file: SandalWoodNewsStories_249.wav\n",
      "Transcription saved for: SandalWoodNewsStories_249.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_249.wav\n",
      "Processing file: SandalWoodNewsStories_257.wav\n",
      "Transcription saved for: SandalWoodNewsStories_257.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_257.wav\n",
      "Processing file: SandalWoodNewsStories_278.wav\n",
      "Transcription saved for: SandalWoodNewsStories_278.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_278.wav\n",
      "Processing file: SandalWoodNewsStories_279.wav\n",
      "Transcription saved for: SandalWoodNewsStories_279.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_279.wav\n",
      "Processing file: SandalWoodNewsStories_280.wav\n",
      "Transcription saved for: SandalWoodNewsStories_280.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_280.wav\n",
      "Processing file: SandalWoodNewsStories_282.wav\n",
      "Transcription saved for: SandalWoodNewsStories_282.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_282.wav\n",
      "Processing file: SandalWoodNewsStories_283.wav\n",
      "Transcription saved for: SandalWoodNewsStories_283.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_283.wav\n",
      "Processing file: SandalWoodNewsStories_284.wav\n",
      "Transcription saved for: SandalWoodNewsStories_284.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_284.wav\n",
      "Processing file: SandalWoodNewsStories_286.wav\n",
      "Transcription saved for: SandalWoodNewsStories_286.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_286.wav\n",
      "Processing file: SandalWoodNewsStories_287.wav\n",
      "Transcription saved for: SandalWoodNewsStories_287.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_287.wav\n",
      "Processing file: SandalWoodNewsStories_291.wav\n",
      "Transcription saved for: SandalWoodNewsStories_291.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_291.wav\n",
      "Processing file: SandalWoodNewsStories_294.wav\n",
      "Transcription saved for: SandalWoodNewsStories_294.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_294.wav\n",
      "Processing file: SandalWoodNewsStories_295.wav\n",
      "Transcription saved for: SandalWoodNewsStories_295.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_295.wav\n",
      "Processing file: SandalWoodNewsStories_296.wav\n",
      "Transcription saved for: SandalWoodNewsStories_296.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_296.wav\n",
      "Processing file: SandalWoodNewsStories_297.wav\n",
      "Transcription saved for: SandalWoodNewsStories_297.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_297.wav\n",
      "Processing file: SandalWoodNewsStories_298.wav\n",
      "Transcription saved for: SandalWoodNewsStories_298.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_298.wav\n",
      "Processing file: SandalWoodNewsStories_299.wav\n",
      "Transcription saved for: SandalWoodNewsStories_299.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_299.wav\n",
      "Processing file: SandalWoodNewsStories_303.wav\n",
      "Transcription saved for: SandalWoodNewsStories_303.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_303.wav\n",
      "Processing file: SandalWoodNewsStories_304.wav\n",
      "Transcription saved for: SandalWoodNewsStories_304.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_304.wav\n",
      "Processing file: SandalWoodNewsStories_305.wav\n",
      "Transcription saved for: SandalWoodNewsStories_305.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_305.wav\n",
      "Processing file: SandalWoodNewsStories_306.wav\n",
      "Transcription saved for: SandalWoodNewsStories_306.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_306.wav\n",
      "Processing file: SandalWoodNewsStories_33.wav\n",
      "Transcription saved for: SandalWoodNewsStories_33.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_33.wav\n",
      "Processing file: SandalWoodNewsStories_35.wav\n",
      "Transcription saved for: SandalWoodNewsStories_35.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_35.wav\n",
      "Processing file: SandalWoodNewsStories_36.wav\n",
      "Transcription saved for: SandalWoodNewsStories_36.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_36.wav\n",
      "Processing file: SandalWoodNewsStories_41.wav\n",
      "Transcription saved for: SandalWoodNewsStories_41.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_41.wav\n",
      "Processing file: SandalWoodNewsStories_42.wav\n",
      "Transcription saved for: SandalWoodNewsStories_42.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_42.wav\n",
      "Processing file: SandalWoodNewsStories_43.wav\n",
      "Transcription saved for: SandalWoodNewsStories_43.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_43.wav\n",
      "Processing file: SandalWoodNewsStories_45.wav\n",
      "Transcription saved for: SandalWoodNewsStories_45.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_45.wav\n",
      "Processing file: SandalWoodNewsStories_46.wav\n",
      "Transcription saved for: SandalWoodNewsStories_46.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_46.wav\n",
      "Processing file: SandalWoodNewsStories_52.wav\n",
      "Transcription saved for: SandalWoodNewsStories_52.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_52.wav\n",
      "Processing file: SandalWoodNewsStories_53.wav\n",
      "Transcription saved for: SandalWoodNewsStories_53.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_53.wav\n",
      "Processing file: SandalWoodNewsStories_6.wav\n",
      "Transcription saved for: SandalWoodNewsStories_6.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_6.wav\n",
      "Processing file: SandalWoodNewsStories_63.wav\n",
      "Transcription saved for: SandalWoodNewsStories_63.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_63.wav\n",
      "Processing file: SandalWoodNewsStories_89.wav\n",
      "Transcription saved for: SandalWoodNewsStories_89.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_89.wav\n",
      "Processing file: SandalWoodNewsStories_9.wav\n",
      "Transcription saved for: SandalWoodNewsStories_9.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_9.wav\n",
      "Processing file: SandalWoodNewsStories_98.wav\n",
      "Transcription saved for: SandalWoodNewsStories_98.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_98.wav\n",
      "Processing file: SandalWoodNewsStories_99.wav\n",
      "Transcription saved for: SandalWoodNewsStories_99.wav\n",
      "Processed audio saved to: ../dataset/preprocessed/SandalWoodNewsStories_99.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import whisper\n",
    "import soundfile as sf  # To save the processed audio as .wav\n",
    "\n",
    "# Set the directory where your .wav files are stored\n",
    "audio_directory = \"../wav_data/\"  # Replace with your actual path\n",
    "processed_audio_directory = \"../dataset/preprocessed/\"  # Folder to save preprocessed audio\n",
    "\n",
    "# Create the processed audio directory if it doesn't exist\n",
    "os.makedirs(processed_audio_directory, exist_ok=True)\n",
    "\n",
    "# Initialize the Whisper model (use a model appropriate for your needs)\n",
    "model = whisper.load_model(\"base\")  # You can choose 'small', 'medium', or 'large' for better accuracy\n",
    "\n",
    "# Function to transcribe audio using Whisper ASR\n",
    "def transcribe_audio(wav_file_path, processed_audio_path):\n",
    "    \"\"\"Transcribe audio using Whisper ASR and save the processed audio.\"\"\"\n",
    "    # Load the audio file with librosa, resampling to 16kHz\n",
    "    audio, sr = librosa.load(wav_file_path, sr=16000)  # Whisper works best with 16kHz audio\n",
    "    \n",
    "    # Save the processed audio to a new location\n",
    "    sf.write(processed_audio_path, audio, sr)  # Saving preprocessed audio\n",
    "\n",
    "    # Use the Whisper model to transcribe the audio\n",
    "    result = model.transcribe(audio, language=\"kn\")  # Language code for Kannada is \"kn\"\n",
    "    return result['text']\n",
    "\n",
    "# Function to save transcription to a text file\n",
    "def save_transcription(wav_file, transcription):\n",
    "    \"\"\"Save transcription to a text file.\"\"\"\n",
    "    transcription_file = wav_file.replace(\".wav\", \"_transcription.txt\")\n",
    "    \n",
    "    # Save the transcription with UTF-8 encoding\n",
    "    with open(transcription_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcription)\n",
    "\n",
    "# Function to process each audio file in the directory\n",
    "def process_audio_files():\n",
    "    # List all .wav files in the audio directory\n",
    "    for wav_file in os.listdir(audio_directory):\n",
    "        if wav_file.endswith(\".wav\"):\n",
    "            wav_file_path = os.path.join(audio_directory, wav_file)\n",
    "            processed_audio_path = os.path.join(processed_audio_directory, wav_file)\n",
    "            \n",
    "            print(f\"Processing file: {wav_file}\")\n",
    "            \n",
    "            # Transcribe the audio and save the processed file\n",
    "            transcription = transcribe_audio(wav_file_path, processed_audio_path)\n",
    "            \n",
    "            # Save the transcription to a text file\n",
    "            save_transcription(wav_file, transcription)\n",
    "            print(f\"Transcription saved for: {wav_file}\")\n",
    "            print(f\"Processed audio saved to: {processed_audio_path}\")\n",
    "\n",
    "# Run the process\n",
    "process_audio_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f5e28-7551-459b-b5fe-321a66d4c14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81079c85-b6c4-4ac4-b2a7-6226d308cec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'httpcore' has no attribute 'SyncHTTPTransport'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_wav_to_text\u001b[39m(file_path, target_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Initialize recognizer and translator\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googletrans\\__init__.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranslator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.0.0-rc.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGCODES, LANGUAGES\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googletrans\\client.py:25\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translated, Detected\n\u001b[0;32m     22\u001b[0m EXCLUDES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mca\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTranslator\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Google Translate ajax API implementation class\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    You have to create an instance of Translator to use this API\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    :type raise_exception: boolean\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, service_urls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39mDEFAULT_USER_AGENT,\n\u001b[0;32m     54\u001b[0m                  raise_exception\u001b[38;5;241m=\u001b[39mDEFAULT_RAISE_EXCEPTION,\n\u001b[0;32m     55\u001b[0m                  proxies: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, httpcore\u001b[38;5;241m.\u001b[39mSyncHTTPTransport] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, timeout: Timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\googletrans\\client.py:55\u001b[0m, in \u001b[0;36mTranslator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTranslator\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Google Translate ajax API implementation class\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    You have to create an instance of Translator to use this API\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    :type raise_exception: boolean\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, service_urls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_agent\u001b[38;5;241m=\u001b[39mDEFAULT_USER_AGENT,\n\u001b[0;32m     54\u001b[0m                  raise_exception\u001b[38;5;241m=\u001b[39mDEFAULT_RAISE_EXCEPTION,\n\u001b[1;32m---> 55\u001b[0m                  proxies: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, httpcore\u001b[38;5;241m.\u001b[39mSyncHTTPTransport] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, timeout: Timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient()\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'httpcore' has no attribute 'SyncHTTPTransport'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "from googletrans import Translator\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_wav_to_text(file_path, target_language='en'):\n",
    "    # Initialize recognizer and translator\n",
    "    recognizer = sr.Recognizer()\n",
    "    translator = Translator()\n",
    "    \n",
    "    # Convert audio file to a format compatible with SpeechRecognition\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    temp_wav_file = \"temp.wav\"\n",
    "    audio.export(temp_wav_file, format=\"wav\")\n",
    "    \n",
    "    # Convert speech to Kannada text\n",
    "    with sr.AudioFile(temp_wav_file) as source:\n",
    "        print(\"Processing audio...\")\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            kannada_text = recognizer.recognize_google(audio_data, language=\"kn-IN\")\n",
    "            print(\"Recognized Kannada text:\", kannada_text)\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Could not understand audio\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Speech Recognition error: {e}\"\n",
    "    \n",
    "    # Translate Kannada text to English\n",
    "    try:\n",
    "        translated_text = translator.translate(kannada_text, src=\"kn\", dest=target_language).text\n",
    "        print(\"Translated English text:\", translated_text)\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        return f\"Translation error: {e}\"\n",
    "\n",
    "# Path to your Kannada WAV file\n",
    "wav_file_path = \"../dataset/preprocessed/SandalWoodNewsStories_1.wav\"\n",
    "\n",
    "# Convert audio to text and translate\n",
    "translated_text = convert_wav_to_text(wav_file_path)\n",
    "if translated_text:\n",
    "    # Save to a text file\n",
    "    with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(translated_text)\n",
    "    print(\"Translation saved to output.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280658c4-4508-461c-85ee-a51ad235268c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b383e-da51-4984-b5d4-51b683dedce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b837a73-2852-43b3-8104-02eabd07e242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4a45a8-077e-4b55-b0ad-d685325b95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the EncoderRNN and AttnDecoderRNN models (ensure these match the original definitions)\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define input and hidden sizes (ensure these match the original)\n",
    "input_size = 5000  # Example input size, replace with actual value\n",
    "output_size = 5000  # Example output size, replace with actual value\n",
    "hidden_size = 256  # Example hidden size, replace with actual value\n",
    "\n",
    "# Instantiate the models\n",
    "encoder_eng = EncoderRNN(input_size, hidden_size).to(device)\n",
    "attn_decoder_eng = AttnDecoderRNN(hidden_size, output_size).to(device)\n",
    "\n",
    "# Load the state dictionaries with map_location to handle CPU-only environments\n",
    "encoder_eng.load_state_dict(torch.load(\"/content/model_enc_eng.dict\", map_location=torch.device('cpu')))\n",
    "attn_decoder_eng.load_state_dict(torch.load(\"/content/model_dec_eng.dict\", map_location=torch.device('cpu')))\n",
    "\n",
    "# Now the models encoder_eng and attn_decoder_eng are ready to be used\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
